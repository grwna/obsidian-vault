- [[#Classical Search|Classical Search]]
- [[#Local Search|Local Search]]
- [[#Variants of Local Search|Variants of Local Search]]
	- [[#Hill-climbing Search|Hill-climbing Search]]
	- [[#Simulated Annealing|Simulated Annealing]]
	- [[#Genetic Algorithm|Genetic Algorithm]]

# Classical Search
Search where the path to the solution matters, where the [[2. Intelligent Agent|agent]] explores the observable search space systematically.
What is known:
- Environment (observable, deterministic)
- States (initial)
- Operators
- Path Cost
- Goal Test

# Local Search
Many problems does not require the full path as the solution, rather only the final state. Local search is good for this.
Formulation/Characteristics:
- Each state is a complete configuration (not path)
- Can move only to immediate neighbours of current state
- No path cost, only state value based on heuristics
- No goal test, maximum state value is the goal

Problem: can get stuck on local maximum (flat or otherwise)

How does local search choose which successor to pick?
- Highest Value (Hill Climb)
- Random (Stochastic)
More on these later

# Variants of Local Search
## Hill-climbing Search
Process:
- Start in a random state
- Continually move in the direction of higher state value
- Terminates when reaching peak
It is like "Climbing everest in thick fog with amnesia"

Hill-climbing Search is then separated into different variations:
### Steepest Ascent HC
Continually choose strictly highest value neighbour, terminates on local maximum (whether that local is global or not).
- Fastest
- Incomplete (very likely to get stuck)

### Sideways Move HC
Allows movement to equal value, not just strictly higher value.
- Fast, slower than steep ascent
- Incomplete (less likely to get stuck)

### Random Restart HC
Does a bunch HC search, each with random initial states. This is good for problems where the global maximum is known, like the N-queens where global maximum = 0 attacking queens.
- Slower
- Complete, if the goal is known
- Incomplete, if the goal is not known

### Stochastic HC
Each movement is not done on **highest** successor, but randomly chosen from available **higher** successors. Choosing the successor is done **nmax** amount of times until the search **cutoff**.
- Even Slower
- Complete, if  **nmax** is high enough


## Simulated Annealing
Combination of complete (random walk) and efficient (hill-climbing). The idea is to escape local maxima by **allowing bad moves**, but gradually decrese the frequency of such bad moves. It is like Stochastic HC that alllows some downhill moves.

The downhill move is done to neighbours that has probability $\ge$ $e^{\frac{\Delta E}{T}}$
- $\Delta E$ - neighbor_value - current_value
- $T$ - temperature that gradually decrease, $T=0$ means the search is finished
Characteristics
- If $\Delta E>0$, move to neighbour
- Else, calculate probability, if probability is less, skip this turn and pick a random successor again.
- If $T$ decreases slow enough, **SA is complete** with a probability approaching 1
## Genetic Algorithm
Improving on Random Restart HC:
- Local Beam Search - Random Restart but work in parallel. The parallel work is not independent.
- Stochastic Beam Search -  In Local Beam, since its an improvement of Random Restart, each parallel work have random initial states, but each successor are chosen based on **their value**. Stochastic beam search changes that by picking successors randomly.

Then, Genetic Algorithm is Stochastic Beam Search, but generated from combination of **two parents**, and works much like evolution (survival of the fittest).

A state or individual is represented as a string over a finite alphabet. Ex. 32752411, to represent the row and column of all queens.

Each state is scored through a **fitness function**.

### Components of GA
- **Initial Population**, starts with *k* randomly generated states as initial population
- **Fitness Function**
- **Successor Function**, pick two parents (randomly) to combine. Next generation of states chosen by:
	- Selection
	- Crossover
	- Mutation
	When the parents are chosen randomly, the fitness value will be the probability of each state to be chosen as parent. Think of an unbalanced roulette wheel. 

### Successor Function of GA
- Selection
Select randomly according to state values (fitness function).

- Cross-Over
For each pair of selected parents, choose a random cross-over index, then cross switch the parents.
Example:
Crossover point: 3
Parent 1: *32752411*
Parent 2: *24748522*

After crossover
Child 1: ***327**48522*
Child 2: ***247**52411*

More popular versions of GA results in only **one child**.

- Mutation
After the cross over, pick a random point (index) of the string, then randomly generate a value to replace the value at that index.